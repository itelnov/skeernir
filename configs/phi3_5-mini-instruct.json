{
    "server": "llamacpp",
    "model_path": "/docker_mount/data/gguf_models/Phi-3.5-mini-instruct.Q4_K_M.gguf",
    "ctx-size": 10000,
    "use_gpu": true,
    "n_gpu_layers": 33,
    "cpu-strict": 0,
    "flash-attn": true,
    "sampling": {
        "temperature": 0.8
    }

}