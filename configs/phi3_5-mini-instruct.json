{
    "agent_graph": "llamacpp_server_chat.py",
    "host_name": "llamacpp",
    "model_path": "/docker_mount/data/gguf_models/Phi-3.5-mini-instruct.Q4_K_M.gguf",    
    "host_params":{
        "ctx-size": 10000,
        "use_gpu": true,
        "n_gpu_layers": 33,
        "cpu-strict": 0,
        "flash-attn": true
    },
    "sampling": {
        "temperature": 0.8
    }

}